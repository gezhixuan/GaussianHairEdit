/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/utils/ops.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd(cast_inputs=torch.float32)
/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/utils/ops.py:51: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, g):  # pylint: disable=arguments-differ
/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/utils/ops.py:61: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input_tensor, gt_grad):
/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/utils/ops.py:68: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_scale):
/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/models/guidance/infedit_guidance.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Seed set to 0
Reading camera 1/305Reading camera 2/305Reading camera 3/305Reading camera 4/305Reading camera 5/305Reading camera 6/305Reading camera 7/305Reading camera 8/305Reading camera 9/305Reading camera 10/305Reading camera 11/305Reading camera 12/305Reading camera 13/305Reading camera 14/305Reading camera 15/305Reading camera 16/305Reading camera 17/305Reading camera 18/305Reading camera 19/305Reading camera 20/305Reading camera 21/305Reading camera 22/305Reading camera 23/305Reading camera 24/305Reading camera 25/305Reading camera 26/305Reading camera 27/305Reading camera 28/305Reading camera 29/305Reading camera 30/305Reading camera 31/305Reading camera 32/305Reading camera 33/305Reading camera 34/305Reading camera 35/305Reading camera 36/305Reading camera 37/305Reading camera 38/305Reading camera 39/305Reading camera 40/305Reading camera 41/305Reading camera 42/305Reading camera 43/305Reading camera 44/305Reading camera 45/305Reading camera 46/305Reading camera 47/305Reading camera 48/305Reading camera 49/305Reading camera 50/305Reading camera 51/305Reading camera 52/305Reading camera 53/305Reading camera 54/305Reading camera 55/305Reading camera 56/305Reading camera 57/305Reading camera 58/305Reading camera 59/305Reading camera 60/305Reading camera 61/305Reading camera 62/305Reading camera 63/305Reading camera 64/305Reading camera 65/305Reading camera 66/305Reading camera 67/305Reading camera 68/305Reading camera 69/305Reading camera 70/305Reading camera 71/305Reading camera 72/305Reading camera 73/305Reading camera 74/305Reading camera 75/305Reading camera 76/305Reading camera 77/305Reading camera 78/305Reading camera 79/305Reading camera 80/305Reading camera 81/305Reading camera 82/305Reading camera 83/305Reading camera 84/305Reading camera 85/305Reading camera 86/305Reading camera 87/305Reading camera 88/305Reading camera 89/305Reading camera 90/305Reading camera 91/305Reading camera 92/305Reading camera 93/305Reading camera 94/305Reading camera 95/305Reading camera 96/305Reading camera 97/305Reading camera 98/305Reading camera 99/305Reading camera 100/305Reading camera 101/305Reading camera 102/305Reading camera 103/305Reading camera 104/305Reading camera 105/305Reading camera 106/305Reading camera 107/305Reading camera 108/305Reading camera 109/305Reading camera 110/305Reading camera 111/305Reading camera 112/305Reading camera 113/305Reading camera 114/305Reading camera 115/305Reading camera 116/305Reading camera 117/305Reading camera 118/305Reading camera 119/305Reading camera 120/305Reading camera 121/305Reading camera 122/305Reading camera 123/305Reading camera 124/305Reading camera 125/305Reading camera 126/305Reading camera 127/305Reading camera 128/305Reading camera 129/305Reading camera 130/305Reading camera 131/305Reading camera 132/305Reading camera 133/305Reading camera 134/305Reading camera 135/305Reading camera 136/305Reading camera 137/305Reading camera 138/305Reading camera 139/305Reading camera 140/305Reading camera 141/305Reading camera 142/305Reading camera 143/305Reading camera 144/305Reading camera 145/305Reading camera 146/305Reading camera 147/305Reading camera 148/305Reading camera 149/305Reading camera 150/305Reading camera 151/305Reading camera 152/305Reading camera 153/305Reading camera 154/305Reading camera 155/305Reading camera 156/305Reading camera 157/305Reading camera 158/305Reading camera 159/305Reading camera 160/305Reading camera 161/305Reading camera 162/305Reading camera 163/305Reading camera 164/305Reading camera 165/305Reading camera 166/305Reading camera 167/305Reading camera 168/305Reading camera 169/305Reading camera 170/305Reading camera 171/305Reading camera 172/305Reading camera 173/305Reading camera 174/305Reading camera 175/305Reading camera 176/305Reading camera 177/305Reading camera 178/305Reading camera 179/305Reading camera 180/305Reading camera 181/305Reading camera 182/305Reading camera 183/305Reading camera 184/305Reading camera 185/305Reading camera 186/305Reading camera 187/305Reading camera 188/305Reading camera 189/305Reading camera 190/305Reading camera 191/305Reading camera 192/305Reading camera 193/305Reading camera 194/305Reading camera 195/305Reading camera 196/305Reading camera 197/305Reading camera 198/305Reading camera 199/305Reading camera 200/305Reading camera 201/305Reading camera 202/305Reading camera 203/305Reading camera 204/305Reading camera 205/305Reading camera 206/305Reading camera 207/305Reading camera 208/305Reading camera 209/305Reading camera 210/305Reading camera 211/305Reading camera 212/305Reading camera 213/305Reading camera 214/305Reading camera 215/305Reading camera 216/305Reading camera 217/305Reading camera 218/305Reading camera 219/305Reading camera 220/305Reading camera 221/305Reading camera 222/305Reading camera 223/305Reading camera 224/305Reading camera 225/305Reading camera 226/305Reading camera 227/305Reading camera 228/305Reading camera 229/305Reading camera 230/305Reading camera 231/305Reading camera 232/305Reading camera 233/305Reading camera 234/305Reading camera 235/305Reading camera 236/305Reading camera 237/305Reading camera 238/305Reading camera 239/305Reading camera 240/305Reading camera 241/305Reading camera 242/305Reading camera 243/305Reading camera 244/305Reading camera 245/305Reading camera 246/305Reading camera 247/305Reading camera 248/305Reading camera 249/305Reading camera 250/305Reading camera 251/305Reading camera 252/305Reading camera 253/305Reading camera 254/305Reading camera 255/305Reading camera 256/305Reading camera 257/305Reading camera 258/305Reading camera 259/305Reading camera 260/305Reading camera 261/305Reading camera 262/305Reading camera 263/305Reading camera 264/305Reading camera 265/305Reading camera 266/305Reading camera 267/305Reading camera 268/305Reading camera 269/305Reading camera 270/305Reading camera 271/305Reading camera 272/305Reading camera 273/305Reading camera 274/305Reading camera 275/305Reading camera 276/305Reading camera 277/305Reading camera 278/305Reading camera 279/305Reading camera 280/305Reading camera 281/305Reading camera 282/305Reading camera 283/305Reading camera 284/305Reading camera 285/305Reading camera 286/305Reading camera 287/305Reading camera 288/305Reading camera 289/305Reading camera 290/305Reading camera 291/305Reading camera 292/305Reading camera 293/305Reading camera 294/305Reading camera 295/305Reading camera 296/305Reading camera 297/305Reading camera 298/305Reading camera 299/305Reading camera 300/305Reading camera 301/305Reading camera 302/305Reading camera 303/305Reading camera 304/305Reading camera 305/305
Reading camera 1/305Reading camera 2/305Reading camera 3/305Reading camera 4/305Reading camera 5/305Reading camera 6/305Reading camera 7/305Reading camera 8/305Reading camera 9/305Reading camera 10/305Reading camera 11/305Reading camera 12/305Reading camera 13/305Reading camera 14/305Reading camera 15/305Reading camera 16/305Reading camera 17/305Reading camera 18/305Reading camera 19/305Reading camera 20/305Reading camera 21/305Reading camera 22/305Reading camera 23/305Reading camera 24/305Reading camera 25/305Reading camera 26/305Reading camera 27/305Reading camera 28/305Reading camera 29/305Reading camera 30/305Reading camera 31/305Reading camera 32/305Reading camera 33/305Reading camera 34/305Reading camera 35/305Reading camera 36/305Reading camera 37/305Reading camera 38/305Reading camera 39/305Reading camera 40/305Reading camera 41/305Reading camera 42/305Reading camera 43/305Reading camera 44/305Reading camera 45/305Reading camera 46/305Reading camera 47/305Reading camera 48/305Reading camera 49/305Reading camera 50/305Reading camera 51/305Reading camera 52/305Reading camera 53/305Reading camera 54/305Reading camera 55/305Reading camera 56/305Reading camera 57/305Reading camera 58/305Reading camera 59/305Reading camera 60/305Reading camera 61/305Reading camera 62/305Reading camera 63/305Reading camera 64/305Reading camera 65/305Reading camera 66/305Reading camera 67/305Reading camera 68/305Reading camera 69/305Reading camera 70/305Reading camera 71/305Reading camera 72/305Reading camera 73/305Reading camera 74/305Reading camera 75/305Reading camera 76/305Reading camera 77/305Reading camera 78/305Reading camera 79/305Reading camera 80/305Reading camera 81/305Reading camera 82/305Reading camera 83/305Reading camera 84/305Reading camera 85/305Reading camera 86/305Reading camera 87/305Reading camera 88/305Reading camera 89/305Reading camera 90/305Reading camera 91/305Reading camera 92/305Reading camera 93/305Reading camera 94/305Reading camera 95/305Reading camera 96/305Reading camera 97/305Reading camera 98/305Reading camera 99/305Reading camera 100/305Reading camera 101/305Reading camera 102/305Reading camera 103/305Reading camera 104/305Reading camera 105/305Reading camera 106/305Reading camera 107/305Reading camera 108/305Reading camera 109/305Reading camera 110/305Reading camera 111/305Reading camera 112/305Reading camera 113/305Reading camera 114/305Reading camera 115/305Reading camera 116/305Reading camera 117/305Reading camera 118/305Reading camera 119/305Reading camera 120/305Reading camera 121/305Reading camera 122/305Reading camera 123/305Reading camera 124/305Reading camera 125/305Reading camera 126/305Reading camera 127/305Reading camera 128/305Reading camera 129/305Reading camera 130/305Reading camera 131/305Reading camera 132/305Reading camera 133/305Reading camera 134/305Reading camera 135/305Reading camera 136/305Reading camera 137/305Reading camera 138/305Reading camera 139/305Reading camera 140/305Reading camera 141/305Reading camera 142/305Reading camera 143/305Reading camera 144/305Reading camera 145/305Reading camera 146/305Reading camera 147/305Reading camera 148/305Reading camera 149/305Reading camera 150/305Reading camera 151/305Reading camera 152/305Reading camera 153/305Reading camera 154/305Reading camera 155/305Reading camera 156/305Reading camera 157/305Reading camera 158/305Reading camera 159/305Reading camera 160/305Reading camera 161/305Reading camera 162/305Reading camera 163/305Reading camera 164/305Reading camera 165/305Reading camera 166/305Reading camera 167/305Reading camera 168/305Reading camera 169/305Reading camera 170/305Reading camera 171/305Reading camera 172/305Reading camera 173/305Reading camera 174/305Reading camera 175/305Reading camera 176/305Reading camera 177/305Reading camera 178/305Reading camera 179/305Reading camera 180/305Reading camera 181/305Reading camera 182/305Reading camera 183/305Reading camera 184/305Reading camera 185/305Reading camera 186/305Reading camera 187/305Reading camera 188/305Reading camera 189/305Reading camera 190/305Reading camera 191/305Reading camera 192/305Reading camera 193/305Reading camera 194/305Reading camera 195/305Reading camera 196/305Reading camera 197/305Reading camera 198/305Reading camera 199/305Reading camera 200/305Reading camera 201/305Reading camera 202/305Reading camera 203/305Reading camera 204/305Reading camera 205/305Reading camera 206/305Reading camera 207/305Reading camera 208/305Reading camera 209/305Reading camera 210/305Reading camera 211/305Reading camera 212/305Reading camera 213/305Reading camera 214/305Reading camera 215/305Reading camera 216/305Reading camera 217/305Reading camera 218/305Reading camera 219/305Reading camera 220/305Reading camera 221/305Reading camera 222/305Reading camera 223/305Reading camera 224/305Reading camera 225/305Reading camera 226/305Reading camera 227/305Reading camera 228/305Reading camera 229/305Reading camera 230/305Reading camera 231/305Reading camera 232/305Reading camera 233/305Reading camera 234/305Reading camera 235/305Reading camera 236/305Reading camera 237/305Reading camera 238/305Reading camera 239/305Reading camera 240/305Reading camera 241/305Reading camera 242/305Reading camera 243/305Reading camera 244/305Reading camera 245/305Reading camera 246/305Reading camera 247/305Reading camera 248/305Reading camera 249/305Reading camera 250/305Reading camera 251/305Reading camera 252/305Reading camera 253/305Reading camera 254/305Reading camera 255/305Reading camera 256/305Reading camera 257/305Reading camera 258/305Reading camera 259/305Reading camera 260/305Reading camera 261/305Reading camera 262/305Reading camera 263/305Reading camera 264/305Reading camera 265/305Reading camera 266/305Reading camera 267/305Reading camera 268/305Reading camera 269/305Reading camera 270/305Reading camera 271/305Reading camera 272/305Reading camera 273/305Reading camera 274/305Reading camera 275/305Reading camera 276/305Reading camera 277/305Reading camera 278/305Reading camera 279/305Reading camera 280/305Reading camera 281/305Reading camera 282/305Reading camera 283/305Reading camera 284/305Reading camera 285/305Reading camera 286/305Reading camera 287/305Reading camera 288/305Reading camera 289/305Reading camera 290/305Reading camera 291/305Reading camera 292/305Reading camera 293/305Reading camera 294/305Reading camera 295/305Reading camera 296/305Reading camera 297/305Reading camera 298/305Reading camera 299/305Reading camera 300/305Reading camera 301/305Reading camera 302/305Reading camera 303/305Reading camera 304/305Reading camera 305/305UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789115405/work/aten/src/ATen/native/TensorShape.cpp:3609.)
FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
[32m[INFO] Using 16bit Automatic Mixed Precision (AMP)[0m
[32m[INFO] GPU available: True (cuda), used: True[0m
[32m[INFO] TPU available: False, using: 0 TPU cores[0m
[32m[INFO] HPU available: False, using: 0 HPUs[0m
[32m[INFO] You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision[0m
[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0][0m
[32m[INFO] 
  | Name            | Type                 | Params | Mode 
-----------------------------------------------------------------
0 | perceptual_loss | PerceptualLoss       | 14.7 M | eval 
1 | text_segmentor  | LangSAMTextSegmentor | 0      | train
-----------------------------------------------------------------
0         Trainable params
14.7 M    Non-trainable params
14.7 M    Total params
58.865    Total estimated model params size (MB)
1         Modules in train mode
58        Modules in eval mode[0m
[32m[INFO] Validation results will be saved to outputs/edit-inf/buzz_cut@20251105-150329/save[0m

loaded pretrained LPIPS loss from threestudio/utils/lpips/vgg.pth
final text_encoder_type: bert-base-uncased
Model loaded from /home/hl106/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth 
 => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:00<00:54,  1.74it/s]  4%|â–         | 4/96 [00:00<00:12,  7.34it/s]  7%|â–‹         | 7/96 [00:00<00:08, 10.88it/s]  9%|â–‰         | 9/96 [00:00<00:07, 11.77it/s] 11%|â–ˆâ–        | 11/96 [00:01<00:06, 12.87it/s] 14%|â–ˆâ–Ž        | 13/96 [00:01<00:06, 12.57it/s] 16%|â–ˆâ–Œ        | 15/96 [00:01<00:05, 13.68it/s] 18%|â–ˆâ–Š        | 17/96 [00:01<00:05, 14.55it/s] 20%|â–ˆâ–‰        | 19/96 [00:01<00:05, 15.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:01<00:04, 16.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:01<00:04, 16.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:02<00:05, 14.17it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:02<00:04, 14.74it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:02<00:04, 15.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:02<00:04, 15.31it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:02<00:04, 15.61it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:02<00:03, 15.72it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:02<00:03, 16.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:02<00:03, 15.47it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:03<00:03, 14.94it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:03<00:03, 14.71it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:03<00:03, 14.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:03<00:03, 14.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:03<00:02, 16.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:03<00:02, 17.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:03<00:02, 18.58it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:03<00:02, 18.30it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:04<00:02, 17.16it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:04<00:02, 16.47it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:04<00:01, 18.34it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:04<00:01, 20.92it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:04<00:01, 23.16it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:04<00:01, 22.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:04<00:00, 23.72it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:04<00:00, 24.74it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:05<00:00, 22.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:05<00:00, 22.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:05<00:00, 21.93it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:05<00:00, 22.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:05<00:00, 23.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:05<00:00, 16.78it/s]
[32m[INFO] Segmentation with prompt: hair[0m
Segment with prompt: hair
  0%|          | 0/96 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
UserWarning: None of the inputs have requires_grad=True. Gradients will be None
FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  1%|          | 1/96 [00:01<02:09,  1.36s/it]  2%|â–         | 2/96 [00:02<01:33,  1.00it/s]  3%|â–Ž         | 3/96 [00:02<01:17,  1.20it/s]  4%|â–         | 4/96 [00:03<01:10,  1.30it/s]  5%|â–Œ         | 5/96 [00:04<01:05,  1.39it/s]  6%|â–‹         | 6/96 [00:04<01:02,  1.44it/s]  7%|â–‹         | 7/96 [00:05<01:06,  1.35it/s]  8%|â–Š         | 8/96 [00:06<01:02,  1.42it/s]  9%|â–‰         | 9/96 [00:06<01:01,  1.41it/s] 10%|â–ˆ         | 10/96 [00:07<00:59,  1.44it/s] 11%|â–ˆâ–        | 11/96 [00:08<00:56,  1.50it/s] 12%|â–ˆâ–Ž        | 12/96 [00:08<00:56,  1.48it/s] 14%|â–ˆâ–Ž        | 13/96 [00:09<00:55,  1.50it/s] 15%|â–ˆâ–        | 14/96 [00:10<00:53,  1.52it/s] 16%|â–ˆâ–Œ        | 15/96 [00:10<00:52,  1.55it/s] 17%|â–ˆâ–‹        | 16/96 [00:11<00:51,  1.57it/s] 18%|â–ˆâ–Š        | 17/96 [00:12<00:51,  1.53it/s] 19%|â–ˆâ–‰        | 18/96 [00:12<00:50,  1.54it/s] 20%|â–ˆâ–‰        | 19/96 [00:13<00:53,  1.43it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:14<00:51,  1.47it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:14<00:53,  1.41it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:15<00:55,  1.33it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:16<00:52,  1.38it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:17<00:50,  1.43it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:17<00:48,  1.46it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:18<00:46,  1.50it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:18<00:44,  1.54it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:19<00:44,  1.53it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:20<00:43,  1.53it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:20<00:42,  1.54it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:21<00:42,  1.53it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:22<00:41,  1.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:22<00:40,  1.54it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:23<00:40,  1.55it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:24<00:39,  1.53it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:24<00:40,  1.47it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:25<00:38,  1.52it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:26<00:37,  1.53it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:26<00:38,  1.50it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:27<00:36,  1.53it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:28<00:35,  1.55it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:28<00:34,  1.56it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:29<00:33,  1.58it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:29<00:32,  1.59it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:30<00:31,  1.61it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:31<00:31,  1.60it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:31<00:31,  1.57it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:32<00:32,  1.47it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:33<00:31,  1.48it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:34<00:31,  1.46it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:34<00:29,  1.51it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:35<00:29,  1.51it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:36<00:29,  1.45it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:36<00:28,  1.48it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:37<00:27,  1.48it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:38<00:27,  1.48it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:38<00:27,  1.42it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:39<00:26,  1.46it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:40<00:25,  1.44it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:40<00:25,  1.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:41<00:24,  1.45it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:42<00:23,  1.47it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:42<00:22,  1.50it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:43<00:21,  1.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:44<00:21,  1.46it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:44<00:20,  1.49it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:45<00:19,  1.49it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:46<00:18,  1.52it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:46<00:17,  1.50it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:47<00:16,  1.53it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:48<00:16,  1.50it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:48<00:15,  1.51it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:49<00:14,  1.54it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:50<00:14,  1.51it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:50<00:13,  1.53it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:51<00:13,  1.50it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:52<00:12,  1.53it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:52<00:11,  1.52it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:53<00:11,  1.47it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:54<00:10,  1.48it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:54<00:10,  1.39it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:55<00:09,  1.41it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:56<00:09,  1.43it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:57<00:08,  1.41it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:57<00:07,  1.45it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:58<00:06,  1.47it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:59<00:06,  1.50it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:59<00:05,  1.44it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [01:00<00:05,  1.39it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [01:01<00:04,  1.40it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [01:01<00:03,  1.41it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [01:02<00:02,  1.45it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [01:03<00:02,  1.47it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [01:03<00:01,  1.51it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [01:04<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:05<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:05<00:00,  1.47it/s]
[32m[INFO] Using prompt [buzz cut] and negative prompt [][0m
[32m[INFO] Using view-dependent prompts [side]:[buzz cut, side view] [front]:[buzz cut, front view] [back]:[buzz cut, back view] [overhead]:[buzz cut, overhead view][0m
FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
[32m[INFO] Loading InfEdit ...[0m
FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_lcm.LCMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[DEBUG] Saved fg to ./debug/fg_gaussians.ply, bg to ./debug/bg_gaussians.ply, exiting after update_mask.
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Loading pipeline components...:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00, 13.62it/s]Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:01<00:01,  2.35it/s]Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:02<00:00,  2.87it/s]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.28it/s]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.57it/s]
[32m[INFO] Loaded InfEdit![0m
PossibleUserWarning: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
PossibleUserWarning: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0: |          | 0/? [00:00<?, ?it/s] Update guidance at global step:  0

  0%|          | 0/96 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 21/96 [00:00<00:00, 206.24it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:00<00:00, 277.75it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:00<00:00, 302.91it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:00<00:00, 293.74it/s]
loaded pretrained LPIPS loss from threestudio/utils/lpips/vgg.pth

  0%|          | 0/15 [00:00<?, ?it/s][A
  7%|â–‹         | 1/15 [00:14<03:24, 14.61s/it][A
 13%|â–ˆâ–Ž        | 2/15 [00:28<03:06, 14.38s/it][A
 20%|â–ˆâ–ˆ        | 3/15 [00:43<02:51, 14.32s/it][A
 27%|â–ˆâ–ˆâ–‹       | 4/15 [00:57<02:38, 14.39s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [01:57<05:08, 30.82s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [02:12<03:49, 25.48s/it][ABlend Cross-Attention Consistency Control at t = 999 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 999 ...
Finished t = 999.
Blend Cross-Attention Consistency Control at t = 939 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 939 ...
Finished t = 939.
Blend Cross-Attention Consistency Control at t = 879 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 879 ...
Finished t = 879.
Blend Cross-Attention Consistency Control at t = 819 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 819 ...
Finished t = 819.
Prediction Consistency Control at t = 759 ...
--step 1: inverse project images to 3d ...
--step 2: render back to images ...
Blend Cross-Attention Consistency Control at t = 759 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 759 ...
Finished t = 759.
Blend Cross-Attention Consistency Control at t = 699 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 699 ...
Finished t = 699.
Cross-Attention Consistency Control at t = 639 ...


  0%|          | 0/4 [00:00<?, ?it/s][A[A

 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:44<02:14, 44.87s/it][A[A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [01:28<01:28, 44.03s/it][A[A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [02:13<00:44, 44.70s/it][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:59<00:00, 44.97s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:59<00:00, 44.80s/it]


  0%|          | 0/1 [00:00<?, ?it/s][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.48s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.48s/it]


  0%|          | 0/6 [00:00<?, ?it/s][A[A

 17%|â–ˆâ–‹        | 1/6 [00:39<03:15, 39.01s/it][A[A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [01:18<02:36, 39.06s/it][A[A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [01:57<01:57, 39.11s/it][A[A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [02:36<01:18, 39.14s/it][A[A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [03:15<00:39, 39.15s/it][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [03:54<00:00, 39.13s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [03:54<00:00, 39.12s/it]

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [10:16<23:23, 175.41s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [10:31<14:28, 124.11s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [10:45<08:58, 89.78s/it] [A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [11:42<06:38, 79.63s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [11:56<03:58, 59.66s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [12:11<02:17, 45.94s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [12:25<01:12, 36.42s/it][ABlend Cross-Attention Consistency Control at t = 639 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 639 ...
Finished t = 639.
Blend Cross-Attention Consistency Control at t = 579 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 579 ...
Finished t = 579.
Blend Cross-Attention Consistency Control at t = 519 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 519 ...
Finished t = 519.
Prediction Consistency Control at t = 459 ...
--step 1: inverse project images to 3d ...
--step 2: render back to images ...
Blend Cross-Attention Consistency Control at t = 459 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 459 ...
Finished t = 459.
Blend Cross-Attention Consistency Control at t = 399 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 399 ...
Finished t = 399.
Blend Cross-Attention Consistency Control at t = 339 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 339 ...
Finished t = 339.
Blend Cross-Attention Consistency Control at t = 279 ...
--step 1: inverse project maps to 3d ...
--step 2: render back to maps ...
Update Latents & Callback at t = 279 ...
Finished t = 279.
Cross-Attention Consistency Control at t = 219 ...


  0%|          | 0/4 [00:00<?, ?it/s][A[A

 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:39<01:57, 39.18s/it][A[A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [01:18<01:18, 39.12s/it][A[A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [01:57<00:39, 39.06s/it][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:36<00:00, 39.11s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:36<00:00, 39.11s/it]


  0%|          | 0/1 [00:00<?, ?it/s][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.03s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.04s/it]


  0%|          | 0/6 [00:00<?, ?it/s][A[A

 17%|â–ˆâ–‹        | 1/6 [00:39<03:15, 39.07s/it][A[A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [01:18<02:37, 39.31s/it][A[A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [01:57<01:58, 39.36s/it][A[A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [02:36<01:18, 39.16s/it][A[A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [03:15<00:39, 39.08s/it][A[A 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [03:55<00:47, 47.05s/it]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [19:49<03:02, 91.49s/it]
Traceback (most recent call last):
  File "launch.py", line 250, in <module>
    main(args, extras)
  File "launch.py", line 193, in main
    trainer.fit(system, datamodule=dm, ckpt_path=cfg.resume)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/core/module.py", line 1306, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/amp.py", line 78, in optimizer_step
    closure_result = closure()
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/systems/VcEdit.py", line 91, in training_step
    result = self.guidance(
  File "/scratch/hl106/zx_workspace/cto/VcEdit/threestudio/models/guidance/infedit_guidance.py", line 154, in __call__
    results = self.pipe(prompt=self.tgt_prompt,
  File "/home/hl106/.conda/envs/vcedit/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/hl106/zx_workspace/cto/VcEdit/infedit/pipeline_con.py", line 232, in __call__
    con_view_attn = torch.cat(con_view_attn, dim=1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 39.49 GiB of which 8.89 GiB is free. Including non-PyTorch memory, this process has 30.59 GiB memory in use. Of the allocated memory 29.07 GiB is allocated by PyTorch, and 1007.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Epoch 0: |          | 0/? [19:53<?, ?it/s]